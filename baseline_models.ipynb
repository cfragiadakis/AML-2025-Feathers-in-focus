{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d875c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a801a3",
   "metadata": {},
   "source": [
    "Let's load the different bird species from the `class_names.npy` file and then the attributes from `attributes.npy` which has for every class 312 features that are explained by the file `attributes.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bd6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_classes = np.load(\"class_names.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b155d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 312)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = np.load('attributes.npy')\n",
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff7e3716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 has_bill_shape::curved_(up_or_down)',\n",
       " '2 has_bill_shape::dagger',\n",
       " '3 has_bill_shape::hooked',\n",
       " '4 has_bill_shape::needle',\n",
       " '5 has_bill_shape::hooked_seabird']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"attributes.txt\", \"r\") as f:\n",
    "    attribute_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "attribute_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b21b06",
   "metadata": {},
   "source": [
    "Unify the attributes files to map for every bird species they're features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc5c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_attributes = {}\n",
    "\n",
    "for class_id in range(attributes.shape[0]):\n",
    "    class_attributes[class_id + 1] = {\n",
    "        attribute_names[i]: attributes[class_id, i] for i in range(len(attribute_names))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd13656",
   "metadata": {},
   "source": [
    "Create a data frame `birds_df` with the class_id and the 312 attrbiutes of each bird class. Then merge it with the class name of each bird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0e2ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>1 has_bill_shape::curved_(up_or_down)</th>\n",
       "      <th>2 has_bill_shape::dagger</th>\n",
       "      <th>3 has_bill_shape::hooked</th>\n",
       "      <th>4 has_bill_shape::needle</th>\n",
       "      <th>5 has_bill_shape::hooked_seabird</th>\n",
       "      <th>6 has_bill_shape::spatulate</th>\n",
       "      <th>7 has_bill_shape::all-purpose</th>\n",
       "      <th>8 has_bill_shape::cone</th>\n",
       "      <th>9 has_bill_shape::specialized</th>\n",
       "      <th>...</th>\n",
       "      <th>303 has_crown_color::pink</th>\n",
       "      <th>304 has_crown_color::orange</th>\n",
       "      <th>305 has_crown_color::black</th>\n",
       "      <th>306 has_crown_color::white</th>\n",
       "      <th>307 has_crown_color::red</th>\n",
       "      <th>308 has_crown_color::buff</th>\n",
       "      <th>309 has_wing_pattern::solid</th>\n",
       "      <th>310 has_wing_pattern::spotted</th>\n",
       "      <th>311 has_wing_pattern::striped</th>\n",
       "      <th>312 has_wing_pattern::multi-colored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.138299</td>\n",
       "      <td>0.065603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.228446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186020</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.025262</td>\n",
       "      <td>0.020669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202095</td>\n",
       "      <td>0.041552</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111144</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>0.202572</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>0.058639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074247</td>\n",
       "      <td>0.146020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190411</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.203609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.017705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.073360</td>\n",
       "      <td>0.138998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152750</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.036478</td>\n",
       "      <td>0.043317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>0.070177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204036</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.158200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_id  1 has_bill_shape::curved_(up_or_down)  2 has_bill_shape::dagger  \\\n",
       "0         1                               0.010638                  0.010638   \n",
       "1         2                               0.000000                  0.011332   \n",
       "2         3                               0.000000                  0.000000   \n",
       "3         4                               0.000000                  0.000000   \n",
       "4         5                               0.000000                  0.035088   \n",
       "\n",
       "   3 has_bill_shape::hooked  4 has_bill_shape::needle  \\\n",
       "0                  0.007092                  0.003546   \n",
       "1                  0.009444                  0.000000   \n",
       "2                  0.007425                  0.000000   \n",
       "3                  0.003861                  0.000000   \n",
       "4                  0.000000                  0.000000   \n",
       "\n",
       "   5 has_bill_shape::hooked_seabird  6 has_bill_shape::spatulate  \\\n",
       "0                          0.138299                     0.065603   \n",
       "1                          0.202095                     0.041552   \n",
       "2                          0.002475                     0.000000   \n",
       "3                          0.003861                     0.013514   \n",
       "4                          0.000000                     0.000000   \n",
       "\n",
       "   7 has_bill_shape::all-purpose  8 has_bill_shape::cone  \\\n",
       "0                       0.000000                0.005319   \n",
       "1                       0.015110                0.005666   \n",
       "2                       0.000000                0.074247   \n",
       "3                       0.005792                0.073360   \n",
       "4                       0.102458                0.070177   \n",
       "\n",
       "   9 has_bill_shape::specialized  ...  303 has_crown_color::pink  \\\n",
       "0                       0.000000  ...                   0.000000   \n",
       "1                       0.000000  ...                   0.006291   \n",
       "2                       0.146020  ...                   0.000000   \n",
       "3                       0.138998  ...                   0.004885   \n",
       "4                       0.000000  ...                   0.000000   \n",
       "\n",
       "   304 has_crown_color::orange  305 has_crown_color::black  \\\n",
       "0                     0.005439                    0.005439   \n",
       "1                     0.000000                    0.111144   \n",
       "2                     0.000000                    0.190411   \n",
       "3                     0.000000                    0.190531   \n",
       "4                     0.000000                    0.204036   \n",
       "\n",
       "   306 has_crown_color::white  307 has_crown_color::red  \\\n",
       "0                    0.228446                  0.000000   \n",
       "1                    0.008388                  0.000000   \n",
       "2                    0.012555                  0.000000   \n",
       "3                    0.000000                  0.000000   \n",
       "4                    0.002458                  0.002458   \n",
       "\n",
       "   308 has_crown_color::buff  309 has_wing_pattern::solid  \\\n",
       "0                   0.000000                     0.186020   \n",
       "1                   0.046135                     0.202572   \n",
       "2                   0.010462                     0.203609   \n",
       "3                   0.000000                     0.152750   \n",
       "4                   0.000000                     0.031640   \n",
       "\n",
       "   310 has_wing_pattern::spotted  311 has_wing_pattern::striped  \\\n",
       "0                       0.009186                       0.025262   \n",
       "1                       0.002665                       0.021323   \n",
       "2                       0.000000                       0.008853   \n",
       "3                       0.006840                       0.036478   \n",
       "4                       0.002751                       0.015132   \n",
       "\n",
       "   312 has_wing_pattern::multi-colored  \n",
       "0                             0.020669  \n",
       "1                             0.058639  \n",
       "2                             0.017705  \n",
       "3                             0.043317  \n",
       "4                             0.158200  \n",
       "\n",
       "[5 rows x 313 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_df = pd.DataFrame.from_dict(class_attributes, orient=\"index\")\n",
    "birds_df.index.name = \"class_id\"\n",
    "birds_df.reset_index(inplace=True)\n",
    "birds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf3875e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.Laysan_Albatross</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.Sooty_Albatross</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.Groove_billed_Ani</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.Crested_Auklet</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        class  id\n",
       "0  001.Black_footed_Albatross   1\n",
       "1        002.Laysan_Albatross   2\n",
       "2         003.Sooty_Albatross   3\n",
       "3       004.Groove_billed_Ani   4\n",
       "4          005.Crested_Auklet   5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.DataFrame.from_dict(bird_classes, orient=\"index\").reset_index()\n",
    "classes.columns = [\"class\", \"id\"]\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f1c339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>class</th>\n",
       "      <th>1 has_bill_shape::curved_(up_or_down)</th>\n",
       "      <th>2 has_bill_shape::dagger</th>\n",
       "      <th>3 has_bill_shape::hooked</th>\n",
       "      <th>4 has_bill_shape::needle</th>\n",
       "      <th>5 has_bill_shape::hooked_seabird</th>\n",
       "      <th>6 has_bill_shape::spatulate</th>\n",
       "      <th>7 has_bill_shape::all-purpose</th>\n",
       "      <th>8 has_bill_shape::cone</th>\n",
       "      <th>...</th>\n",
       "      <th>303 has_crown_color::pink</th>\n",
       "      <th>304 has_crown_color::orange</th>\n",
       "      <th>305 has_crown_color::black</th>\n",
       "      <th>306 has_crown_color::white</th>\n",
       "      <th>307 has_crown_color::red</th>\n",
       "      <th>308 has_crown_color::buff</th>\n",
       "      <th>309 has_wing_pattern::solid</th>\n",
       "      <th>310 has_wing_pattern::spotted</th>\n",
       "      <th>311 has_wing_pattern::striped</th>\n",
       "      <th>312 has_wing_pattern::multi-colored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.138299</td>\n",
       "      <td>0.065603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.228446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186020</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.025262</td>\n",
       "      <td>0.020669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>002.Laysan_Albatross</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202095</td>\n",
       "      <td>0.041552</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111144</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>0.202572</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>0.058639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>003.Sooty_Albatross</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190411</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.203609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.017705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>004.Groove_billed_Ani</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.073360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152750</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.036478</td>\n",
       "      <td>0.043317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>005.Crested_Auklet</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>0.070177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204036</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.158200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_id                       class  \\\n",
       "0         1  001.Black_footed_Albatross   \n",
       "1         2        002.Laysan_Albatross   \n",
       "2         3         003.Sooty_Albatross   \n",
       "3         4       004.Groove_billed_Ani   \n",
       "4         5          005.Crested_Auklet   \n",
       "\n",
       "   1 has_bill_shape::curved_(up_or_down)  2 has_bill_shape::dagger  \\\n",
       "0                               0.010638                  0.010638   \n",
       "1                               0.000000                  0.011332   \n",
       "2                               0.000000                  0.000000   \n",
       "3                               0.000000                  0.000000   \n",
       "4                               0.000000                  0.035088   \n",
       "\n",
       "   3 has_bill_shape::hooked  4 has_bill_shape::needle  \\\n",
       "0                  0.007092                  0.003546   \n",
       "1                  0.009444                  0.000000   \n",
       "2                  0.007425                  0.000000   \n",
       "3                  0.003861                  0.000000   \n",
       "4                  0.000000                  0.000000   \n",
       "\n",
       "   5 has_bill_shape::hooked_seabird  6 has_bill_shape::spatulate  \\\n",
       "0                          0.138299                     0.065603   \n",
       "1                          0.202095                     0.041552   \n",
       "2                          0.002475                     0.000000   \n",
       "3                          0.003861                     0.013514   \n",
       "4                          0.000000                     0.000000   \n",
       "\n",
       "   7 has_bill_shape::all-purpose  8 has_bill_shape::cone  ...  \\\n",
       "0                       0.000000                0.005319  ...   \n",
       "1                       0.015110                0.005666  ...   \n",
       "2                       0.000000                0.074247  ...   \n",
       "3                       0.005792                0.073360  ...   \n",
       "4                       0.102458                0.070177  ...   \n",
       "\n",
       "   303 has_crown_color::pink  304 has_crown_color::orange  \\\n",
       "0                   0.000000                     0.005439   \n",
       "1                   0.006291                     0.000000   \n",
       "2                   0.000000                     0.000000   \n",
       "3                   0.004885                     0.000000   \n",
       "4                   0.000000                     0.000000   \n",
       "\n",
       "   305 has_crown_color::black  306 has_crown_color::white  \\\n",
       "0                    0.005439                    0.228446   \n",
       "1                    0.111144                    0.008388   \n",
       "2                    0.190411                    0.012555   \n",
       "3                    0.190531                    0.000000   \n",
       "4                    0.204036                    0.002458   \n",
       "\n",
       "   307 has_crown_color::red  308 has_crown_color::buff  \\\n",
       "0                  0.000000                   0.000000   \n",
       "1                  0.000000                   0.046135   \n",
       "2                  0.000000                   0.010462   \n",
       "3                  0.000000                   0.000000   \n",
       "4                  0.002458                   0.000000   \n",
       "\n",
       "   309 has_wing_pattern::solid  310 has_wing_pattern::spotted  \\\n",
       "0                     0.186020                       0.009186   \n",
       "1                     0.202572                       0.002665   \n",
       "2                     0.203609                       0.000000   \n",
       "3                     0.152750                       0.006840   \n",
       "4                     0.031640                       0.002751   \n",
       "\n",
       "   311 has_wing_pattern::striped  312 has_wing_pattern::multi-colored  \n",
       "0                       0.025262                             0.020669  \n",
       "1                       0.021323                             0.058639  \n",
       "2                       0.008853                             0.017705  \n",
       "3                       0.036478                             0.043317  \n",
       "4                       0.015132                             0.158200  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_df = birds_df.merge(classes, left_on=\"class_id\", right_on=\"id\")\n",
    "birds_df = birds_df.drop(columns=[\"id\"])\n",
    "\n",
    "# Reorder columns to have class_id and class first\n",
    "cols = [\"class_id\", \"class\"] + [c for c in birds_df.columns if c not in [\"class_id\", \"class\"]]\n",
    "birds_df = birds_df[cols]\n",
    "birds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313c468d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_path  label\n",
       "0  ./train_images/1.jpg      1\n",
       "1  ./train_images/2.jpg      1\n",
       "2  ./train_images/3.jpg      1\n",
       "3  ./train_images/4.jpg      1\n",
       "4  ./train_images/5.jpg      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = pd.read_csv(\"train_images.csv\")\n",
    "images_df['image_path'] = '.' + images_df['image_path']\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838bccf",
   "metadata": {},
   "source": [
    "### Load training metadata and create train/validation split\n",
    "\n",
    "In this step, we load the `train_images.csv` file that contains the image paths and labels.  \n",
    "Then we create a stratified train/validation split so that all 200 classes are represented proportionally in both sets.  \n",
    "This split will be used to train the CNN on `train_images` and evaluate it on `val_images`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29378958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 786)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images, val_images = train_test_split(\n",
    "    images_df,\n",
    "    test_size=0.2,\n",
    "    stratify=images_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "len(train_images), len(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b61f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>./train_images/1250.jpg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>./train_images/3883.jpg</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>./train_images/687.jpg</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>./train_images/1453.jpg</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>./train_images/2358.jpg</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_path  label\n",
       "1249  ./train_images/1250.jpg     42\n",
       "3882  ./train_images/3883.jpg    193\n",
       "686    ./train_images/687.jpg     23\n",
       "1452  ./train_images/1453.jpg     49\n",
       "2357  ./train_images/2358.jpg     85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213bdfdd",
   "metadata": {},
   "source": [
    "### Define Image Transformations for Training and Validation\n",
    "\n",
    "Before training a CNN, all images need to be preprocessed in a consistent way.  \n",
    "Here, we define two sets of transformations:\n",
    "\n",
    "**Training transforms**\n",
    "- **Resize to 224×224:** ResNet models expect fixed-size input.\n",
    "- **Random horizontal flip:** A simple data augmentation step to help the model generalize.\n",
    "- **Convert to tensor:** Converts the image to a PyTorch tensor with values in `[0,1]`.\n",
    "- **Normalize with ImageNet statistics:** Since ResNet18 was pretrained on ImageNet, the same normalization must be applied for best performance.\n",
    "\n",
    "**Validation transforms**\n",
    "- Same as above but **without augmentation**, to ensure a stable and deterministic evaluation.\n",
    "\n",
    "These transforms prepare raw images so they can be passed into the CNN during training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5aed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# image transforms (basic baseline)\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c42e39",
   "metadata": {},
   "source": [
    "### Create a custom PyTorch Dataset for bird images\n",
    "\n",
    "Here we define a `BirdsDataset` class that:\n",
    "- Reads the image path and label from the DataFrame rows.\n",
    "- Loads each image with PIL.\n",
    "- Applies the appropriate transform (train or validation).\n",
    "- Converts labels from 1–200 to 0–199 so they work with `nn.CrossEntropyLoss`.\n",
    "\n",
    "This Dataset will be used together with a DataLoader to efficiently feed batches to the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd4953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdsDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, use_attributes=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.use_attributes = use_attributes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"image_path\"]\n",
    "        label = int(row[\"label\"]) - 1\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fb60b",
   "metadata": {},
   "source": [
    "### Wrap Datasets in DataLoaders\n",
    "\n",
    "Now we create `DataLoader` objects for the training and validation sets.  \n",
    "DataLoaders handle:\n",
    "- Shuffling (for training),\n",
    "- Batching,\n",
    "- Parallel loading of images (with `num_workers`).\n",
    "\n",
    "These will be used directly in the training and evaluation loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b75544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = BirdsDataset(train_images, transform=train_transform)\n",
    "val_dataset   = BirdsDataset(val_images,   transform=val_transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a487fe7c",
   "metadata": {},
   "source": [
    "### Define Device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea1448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bec69a-23e1-43f3-8ce9-f805bc126de5",
   "metadata": {},
   "source": [
    "## Define two models: Simple CNN and ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b607d98",
   "metadata": {},
   "source": [
    "### Building a simple CNN from scratch (baseline CNN)\n",
    "\n",
    "Before comparing with pretrained models like ResNet18, it's useful to build a classic convolutional neural network from scratch.  \n",
    "This gives a \"true baseline\" — a model that only learns from the bird training images, without any prior ImageNet knowledge.\n",
    "\n",
    "The custom CNN below contains:\n",
    "- Three convolutional blocks (Conv → BatchNorm → ReLU → MaxPool)\n",
    "- A flatten layer\n",
    "- Two fully-connected layers\n",
    "- A final output layer with 200 logits (one per bird species)\n",
    "\n",
    "This model is lightweight, easy to understand, and suitable for verifying that the training loop and data pipeline work correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c45182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)    # 224 → 112\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)    # 112 → 56\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)    # 56 → 28\n",
    "        )\n",
    "\n",
    "        # 28×28 feature map with 128 channels → flatten\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)  # flatten all except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d398f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = SimpleCNN(num_classes=200).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "CNN_optimizer = torch.optim.Adam(CNN_model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f7d8b",
   "metadata": {},
   "source": [
    "### Define a baseline CNN model (ResNet18)\n",
    "\n",
    "As a strong baseline, we use a pretrained `ResNet18` from `torchvision.models`:\n",
    "- We load ImageNet-pretrained weights.\n",
    "- We replace the final fully-connected layer so it outputs 200 logits (one per bird class).\n",
    "- The rest of the network acts as a feature extractor.\n",
    "\n",
    "This gives a solid starting point for accuracy without heavy custom architecture work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6380dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet18\n",
    "weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "ResNet_model = models.resnet18(weights=weights)\n",
    "\n",
    "# Replace the final layer to match 200 classes\n",
    "num_features = ResNet_model.fc.in_features\n",
    "ResNet_model.fc = nn.Linear(num_features, 200)\n",
    "\n",
    "ResNet_model = ResNet_model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ResNet_optimizer = torch.optim.Adam(ResNet_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b211d20",
   "metadata": {},
   "source": [
    "### Define training and validation loops\n",
    "\n",
    "Here we implement two functions:\n",
    "\n",
    "- `train_one_epoch`: runs one epoch over the training set, updates weights, and tracks loss and accuracy.\n",
    "- `evaluate`: runs one full pass over the validation set without gradient updates, and reports loss and accuracy.\n",
    "\n",
    "These utilities keep the main training loop clean and readable, and allow easy reuse later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0a9c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Val\", leave=False):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9bf68",
   "metadata": {},
   "source": [
    "### Train the CNN baseline model and monitor accuracy\n",
    "\n",
    "We run the training for a few epochs.  \n",
    "For each epoch, we log:\n",
    "- Training loss and accuracy\n",
    "- Validation loss and accuracy\n",
    "\n",
    "We also keep track of the best validation accuracy and save the model weights whenever a new best score is reached.  \n",
    "This gives me a first baseline performance for the bird classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f38f4fba-d4ed-4529-9456-0816845b64a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 6.6179, acc: 0.0073\n",
      "  Val    | loss: 5.2867, acc: 0.0051\n",
      "New best model saved with val_acc = 0.0051\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 5.2842, acc: 0.0070\n",
      "  Val    | loss: 5.2782, acc: 0.0115\n",
      "New best model saved with val_acc = 0.0115\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 5.2738, acc: 0.0076\n",
      "  Val    | loss: 5.2830, acc: 0.0153\n",
      "New best model saved with val_acc = 0.0153\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 5.2472, acc: 0.0143\n",
      "  Val    | loss: 5.2639, acc: 0.0115\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 5.2037, acc: 0.0169\n",
      "  Val    | loss: 5.2339, acc: 0.0216\n",
      "New best model saved with val_acc = 0.0216\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(CNN_model, train_loader, CNN_optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(CNN_model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"  Train  | loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val    | loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best ResNet_model\n",
    "    if val_acc > best_val_acc:  \n",
    "        best_val_acc = val_acc\n",
    "        torch.save(CNN_model.state_dict(), \"best_CNN_baseline.pt\")\n",
    "        print(f\"New best model saved with val_acc = {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5099460-18ba-447c-931e-4e57afe3c980",
   "metadata": {},
   "source": [
    "### Train the ResNet18 baseline model and monitor accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8486ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 4.6993, acc: 0.1127\n",
      "  Val    | loss: 3.7666, acc: 0.2761\n",
      "New best model saved with val_acc = 0.2761\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 3.1974, acc: 0.4427\n",
      "  Val    | loss: 2.9975, acc: 0.4262\n",
      "New best model saved with val_acc = 0.4262\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 2.3340, acc: 0.6366\n",
      "  Val    | loss: 2.6871, acc: 0.4758\n",
      "New best model saved with val_acc = 0.4758\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 1.6966, acc: 0.7707\n",
      "  Val    | loss: 2.2902, acc: 0.5229\n",
      "New best model saved with val_acc = 0.5229\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train  | loss: 1.2163, acc: 0.8774\n",
      "  Val    | loss: 2.1153, acc: 0.5394\n",
      "New best model saved with val_acc = 0.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(ResNet_model, train_loader, ResNet_optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(ResNet_model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"  Train  | loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val    | loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best ResNet_model\n",
    "    if val_acc > best_val_acc:  \n",
    "        best_val_acc = val_acc\n",
    "        torch.save(ResNet_model.state_dict(), \"best_resnet18_baseline.pt\")\n",
    "        print(f\"New best model saved with val_acc = {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb1136-7208-4f13-b776-37563eff0ce9",
   "metadata": {},
   "source": [
    "### Re-load the ResNet18 model (No need to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed50a0e-8d06-4ec3-9c6a-3e3ad0a4c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_model = models.resnet18(weights=None)  # initialize architecture\n",
    "num_features = ResNet_model.fc.in_features\n",
    "ResNet_model.fc = nn.Linear(num_features, 200)\n",
    "\n",
    "ResNet_model.load_state_dict(torch.load(\"best_resnet18_baseline.pt\", map_location=device))\n",
    "ResNet_model = ResNet_model.to(device)\n",
    "ResNet_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fb120-0515-47e8-b62f-ed38036f222d",
   "metadata": {},
   "source": [
    "## Load `Falconsai/nsfw_image_detection` and adapt it for 200 bird classes\n",
    "\n",
    "The `Falconsai/nsfw_image_detection` model is a ViT-based image classifier originally trained for 2 classes\n",
    "(`normal` vs `nsfw`). I reuse the pretrained backbone and:\n",
    "\n",
    "1. Load the model and its image processor from Hugging Face.\n",
    "2. Replace the final classification layer (`classifier`) so that it outputs 200 logits (one per bird class).\n",
    "3. Update the config metadata (`num_labels`, `id2label`, `label2id`) for consistency.\n",
    "\n",
    "This gives me a strong transformer-based model specialized for my 200 bird classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3634a60f-09da-4418-aaea-91fce90bf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install transformers\n",
    "\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e3a1371-6e68-4f9b-9bdd-7eae72e83366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original num_labels: 2\n",
      "Adapted num_labels: 200\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model_name = \"Falconsai/nsfw_image_detection\"\n",
    "\n",
    "# Image processor: handles resize, normalize, etc. for ViT\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Load ViT-based image classification model\n",
    "vit_model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "print(\"Original num_labels:\", vit_model.config.num_labels)\n",
    "\n",
    "# Replace classifier head to output 200 classes\n",
    "num_features = vit_model.classifier.in_features\n",
    "vit_model.classifier = nn.Linear(num_features, 200)\n",
    "\n",
    "# Update config info\n",
    "vit_model.config.num_labels = 200\n",
    "vit_model.num_labels = 200\n",
    "vit_model.config.id2label = {i: f\"class_{i+1}\" for i in range(200)}\n",
    "vit_model.config.label2id = {v: k for k, v in vit_model.config.id2label.items()}\n",
    "\n",
    "vit_model = vit_model.to(device)\n",
    "print(\"Adapted num_labels:\", vit_model.config.num_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c675c9a-2cb9-40da-af1a-99009661fef8",
   "metadata": {},
   "source": [
    "### Create a Dataset that uses the ViT image processor\n",
    "\n",
    "For the ViT model, I no longer use the `torchvision` transforms.\n",
    "Instead, I use the Hugging Face `AutoImageProcessor`, which:\n",
    "\n",
    "- Resizes the image to the correct resolution (224×224 for ViT)\n",
    "- Converts it to a tensor\n",
    "- Applies the exact normalization used during pretraining\n",
    "\n",
    "I define a `BirdsDatasetViT` class that:\n",
    "- Takes the same `train_df` / `val_df` as before (with `image_path` and `label`)\n",
    "- Loads each image with PIL\n",
    "- Runs the image through the processor to get `pixel_values`\n",
    "- Returns `(pixel_values, label)` where labels are 0–199\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b66c1ed-18bf-4706-80d6-9da57494c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class BirdsDatasetViT(Dataset):\n",
    "    def __init__(self, df, processor, base_dir=\".\", label_col=\"label\", path_col=\"image_path\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.base_dir = base_dir\n",
    "        self.label_col = label_col\n",
    "        self.path_col = path_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        raw_path = str(row[self.path_col])\n",
    "        # Fix leading \"/\" → make it relative\n",
    "        rel_path = raw_path.lstrip(\"/\")\n",
    "        img_path = os.path.join(self.base_dir, rel_path)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Use HF processor to get ViT-ready pixel_values\n",
    "        inputs = self.processor(images=img, return_tensors=\"pt\")\n",
    "        pixel_values = inputs[\"pixel_values\"].squeeze(0)  # (3, H, W)\n",
    "\n",
    "        label = int(row[self.label_col]) - 1  # 1–200 → 0–199\n",
    "\n",
    "        return pixel_values, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5904d4b-7328-4942-b867-3347891a1743",
   "metadata": {},
   "source": [
    "### Create DataLoaders for the ViT-based model\n",
    "\n",
    "Now I wrap the `BirdsDatasetViT` in PyTorch DataLoaders.\n",
    "On macOS, using `num_workers=0` avoids multiprocess issues while debugging.\n",
    "These loaders will feed ViT-ready `pixel_values` and labels into the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35b79aa4-e444-4dd3-aebb-9c854264e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Adjust this path: the folder that contains `train_images/`\n",
    "# If your notebook is already in the project root, \".\" is fine.\n",
    "base_dir = \".\"  \n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset_vit = BirdsDatasetViT(train_images, processor=processor, base_dir=base_dir)\n",
    "val_dataset_vit   = BirdsDatasetViT(val_images,   processor=processor, base_dir=base_dir)\n",
    "\n",
    "train_loader_vit = DataLoader(\n",
    "    train_dataset_vit,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader_vit = DataLoader(\n",
    "    val_dataset_vit,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539b415-37fc-40d4-a848-32f0686d5d01",
   "metadata": {},
   "source": [
    "### Training and validation loops for the ViT model\n",
    "\n",
    "The training logic is the same as before, but the forward pass changes slightly:\n",
    "\n",
    "- For ResNet: `outputs = model(images)`\n",
    "- For ViT (Hugging Face): `outputs = vit_model(pixel_values=images)`\n",
    "\n",
    "From `outputs`, I use `outputs.logits` and compute cross-entropy loss as usual.\n",
    "The rest of the loop (accuracy computation, backprop, logging) is unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f36835-85bb-4713-963a-8e5908156138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch_vit(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for pixel_values, labels in tqdm(loader, desc=\"Train (ViT)\", leave=False):\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * pixel_values.size(0)\n",
    "        _, preds = logits.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate_vit(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pixel_values, labels in tqdm(loader, desc=\"Val (ViT)\", leave=False):\n",
    "            pixel_values = pixel_values.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item() * pixel_values.size(0)\n",
    "            _, preds = logits.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a6a78-6c71-4cd9-907d-bcff31a08bc7",
   "metadata": {},
   "source": [
    "### Fine-tune the Falconsai ViT as a \"ceiling\" model\n",
    "\n",
    "Now I fine-tune the adapted ViT model on the bird dataset.\n",
    "This model:\n",
    "\n",
    "- Starts from a powerful Vision Transformer backbone\n",
    "- Has a new classification head for 200 bird classes\n",
    "- Is expected to perform at least as well as ResNet18, and possibly better,\n",
    "  giving me an approximate performance \"ceiling\" for this assignment.\n",
    "\n",
    "I reuse the same training hyperparameters as a starting point and monitor train/validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17d712-7302-4431-8a55-a0dc5d23ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (ViT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (ViT):   1%|▎                            | 1/99 [01:20<2:11:58, 80.80s/it]"
     ]
    }
   ],
   "source": [
    "criterion_vit = nn.CrossEntropyLoss()\n",
    "optimizer_vit = torch.optim.Adam(vit_model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs_vit = 5\n",
    "best_val_acc_vit = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs_vit + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs_vit} (ViT)\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch_vit(vit_model, train_loader_vit, optimizer_vit, criterion_vit, device)\n",
    "    val_loss, val_acc = evaluate_vit(vit_model, val_loader_vit, criterion_vit, device)\n",
    "\n",
    "    print(f\"  Train (ViT) | loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val   (ViT) | loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc_vit:\n",
    "        best_val_acc_vit = val_acc\n",
    "        torch.save(vit_model.state_dict(), \"vit_nsfw_birds_state_dict.pt\")\n",
    "        print(f\" New best ViT model saved with val_acc = {best_val_acc_vit:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e10e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
